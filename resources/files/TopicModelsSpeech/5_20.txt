ICASSP 2010 Dallas TX LANGUAGE MODEL ADAPTATION USING WWW DOCUMENTS OBTAINED BY UTTERANCE BASED QUERIES Andreas Tsiartas Panayiotis Georgiou and Shrikanth Narayanan Speech Analysis and Interpretation Laboratory Department of Electrical Engineering University of Southern California Los Angeles CA 90089 tsiartas usc edu georgiou sipi usc edu shri sipi usc edu ABSTRACT In this paper we consider the estimation of topic for extracting keywords from the ASR hypothesis transcripts include that proposed by Lecorve et al 3 In spite of these approaches being unsupervised they heavily depend on the quality of the ASR hypothesis transcripts Also such approaches are not appealing for real time systems since downloading documents and re estimating the LMs can be computationally expensive and time consuming While the efforts described above assume that no prior topic information is available various other methods have been proposed to generate queries from a training text using language 978 1 4244 4296 6 10 25 5406 ICASSP 2010 language model exists For instance Wan et al 10 proposed two methods for selecting topic 1 If T is odd one of the two sets will have one more element than the other set Similarly we estimate the distribution of the utterances in T2 and we denote the probability of an event u in T2 as P u T2 Likewise we estimate the distribution of the utterances in Q and we denote the probability of an event u in Q as P u Q In the second step we rank all utterances u T2 in descending order according to the value given by D u Q T1 which is 5407 MFCCs and energy along 0 4 Relative Frequency one utterance per line Also 0 35 0 3 0 25 0 2 0 15 0 1 0 05 Proposed utterance based Keyword based 2 2 1 Keyword based 6 2 0 0 2 4 6 8 10 Log10 scaled number of documents available per query Fig 2 The normalized histogram of the log10 scaled number of documents available per query This histogram does not include samples when zero documents were returned The end goal of the query retrieval process is to obtain the required data but also the most relevant data therefore the appropriate queries can 5408 0 7 Relative Frequency 0 6 0 5 0 4 0 3 0 2 0 1 0 0 Proposed utterance based Keyword based 2 2 1 Keyword based 6 2 ics as explained in section 2 2 In addition the performance boost comes from the fact that utterance based queries return documents that are closer to the domain of interest 6 CONCLUSION In this paper we have introduced a novel method for generating high quality in domain queries that do not require any language 7 REFERENCES Log10 scaled number of words per document 2 4 6 8 Fig 3 The normalized histogram of the number of words per document in log 10 scale of more topic 35 34 5 34 33 5 Proposed utterance based Keyword based 2 2 1 Keyword based 6 2 33 32 5 32 31 5 31 0 50 100 150 Number of words in millions used in LM training Fig 4 WER against the number of words used to train the LM 5 2 Results The ASR performance as a function of the number of the words used in training the Web LM is shown 1 Berger A and Miller R Just in time language modelling in Proceedings of the IEEE International Conference on Acoustics Speech and Signal Processing Seattle WA USA 1998 vol II pp WER 5409 