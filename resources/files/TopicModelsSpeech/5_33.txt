SMLI TR2004 0811 c 2004 SUN MICROSYSTEMS INC 1 Sphinx 4 A Flexible Open Source Framework for Speech Recognition Willie Walker Paul Lamere Philip Kwok Bhiksha Raj Rita Singh Evandro Gouvea Peter Wolf Joe Woelfel Abstract Sphinx 4 is a flexible modular and pluggable framework to help foster new innovations in the core research of hidden Markov model HMM recognition systems The design of Sphinx 4 is based on patterns that have emerged from the design of past systems as well as new requirements based on areas that researchers currently want to explore To exercise this framework and to provide researchers with a research ready system Sphinx 4 also includes several implementations of both simple and state of the art techniques The framework and the implementations are all freely available via open source I I NTRODUCTION W HEN researchers approach the problem of core speech recognition research they are often faced with the problem of needing to develop an entire system from scratch even if they only want to explore one facet of the field Open source speech recognition systems are available such as HTK 1 ISIP 2 AVCSR 3 and earlier versions of the Sphinx systems W Walker P Lamere and P Kwok are with Sun Microsystems E Gouvea and R Singh are with Carnegie Mellon University B Raj P Wolf and J Woelfel are with Mitsubishi Electric Research Labs SMLI TR2004 0811 c 2004 SUN MICROSYSTEMS INC 2 Fig 1 Sphinx 4 Decoder Framework The main blocks are the FrontEnd the Decoder and the Linguist Supporting blocks include the ConfigurationManager and the Tools blocks The communication between the blocks as well as communication with an application is depicted III S PHINX 4 F RAMEWORK The Sphinx 4 framework has been designed with a high degree of flexibility and modularity Figure 1 shows the overall architecture of the system Each labeled element in Figure 1 represents a module that can be easily replaced allowing researchers to experiment with different module implementations without needing to modify other portions of the system There are three primary modules in the Sphinx 4 framework the FrontEnd the Decoder and the Linguist The FrontEnd takes one or more input signals and parameterizes them into a sequence of Features The Linguist translates any type of standard language model along with pronunciation information from the Dictionary and structural information from one or more sets of AcousticModels into a SearchGraph The SearchManager in the Decoder uses the Features from the FrontEnd and the SearchGraph from the Linguist to perform the actual decoding generating Results At any time prior to or during the recognition process the application can issue Controls to each of the modules effectively becoming a partner in the recognition process The Sphinx 4 system is like most speech recognition systems in that it has a large number of configurable parameters such as search beam size for tuning the system performance The Sphinx 4 ConfigurationManager is used to configure such parameters Unlike other systems however the ConfigurationManager also gives Sphinx 4 the ability to dynamically load and configure modules at run time yielding a flexible and pluggable system For example Sphinx 4 is typically configured with a FrontEnd see Section IV that produces Mel Frequency Cepstral Coefficients MFCCs 15 Using the ConfigurationManager however it is possible to reconfigure Sphinx 4 to construct a different FrontEnd that produces Perceptual Linear Prediction coefficients PLP 16 without needing to modify any source code or to recompile the system To give applications and developers the ability to track decoder statistics such as word error rate 17 runtime speed and memory usage Sphinx 4 provides a number of Tools As with the rest of the system the Tools are highly configurable allowing users to perform a wide range of system analysis Furthermore the Tools also provides an interactive runtime environment that allows users to modify the parameters of the system while the system is running allowing for rapid experimentation with various parameters settings Sphinx 4 also provides support for Utilities that support application level processing of recognition results For example these utilities include support for obtaining result lattices confidence scores and natural language understanding IV F RONT E ND The purpose of the FrontEnd is to parameterize an Input signal e g audio into a sequence of output Features As illustrated in Figure 2 the FrontEnd comprises one or more parallel chains of replaceable communicating signal processing modules called DataProcessors Supporting multiple chains permits simultaneous computation of different types of parameters from the same or different input signals This enables the creation of systems that can simultaneously decode using different parameter types such as MFCC and PLP and even parameter types derived from non speech signals such as video 3 SMLI TR2004 0811 c 2004 SUN MICROSYSTEMS INC 3 Fig 2 Sphinx 4 FrontEnd The FrontEnd comprises one or more parallel chains of communicating DataProcessors Like the ISIP 2 system each DataProcessor in the FrontEnd provides an input and an output that can be connected to another DataProcessor permitting arbitrarily long sequences of chains The inputs and outputs of each DataProcessor are generic Data objects that encapsulate processed input data as well as markers that indicate data classification events such as end point detection The last DataProcessor in each chain is responsible for producing a Data object composed of parameterized signals called Features to be used by the Decoder Like the AVCSR system 3 Sphinx 4 permits the ability to produce parallel sequences of features Sphinx 4 is unique however in that it allows for an arbitrary number of parallel streams The communication between blocks follows a pull design With a pull design a DataProcessor requests input from an earlier module only when needed as opposed to the more conventional push design where a module propagates its output to the succeeding module as soon as it is generated This pull design enables the processors to perform buffering allowing consumers to look forwards or backwards in time The ability to look forwards or backwards in time not only permits the Decoder to perform frame synchronous Viterbi searches 18 but also allows the decoder to perform other types of searches such as depth first and A 19 Within the generic FrontEnd framework the Sphinx 4 provides a suite of DataProcessors that implement common signal processing techniques These implementations include support for the following reading from a variety of input formats for batch mode operation reading from the system audio input device for live mode operation preemphasis windowing with a raised cosine transform e g Hamming and Hanning windows discrete fourier transform via FFT mel frequency filtering bark frequency warping discrete cosine transform DCT linear predictive encoding LPC end pointing cepstral mean normalization CMN mel cepstra frequency coefficient extraction MFCC and perceptual linear prediction coefficient extraction PLP Using the ConfigurationManager described in Section III users can chain the Sphinx 4 DataProcessors together in any manner as well as incorporate DataProcessor implementations of their own design As such the modular and pluggable nature of Sphinx 4 not only applies to the higher level structure of Sphinx 4 but also applies to the higher level modules themselves i e the FrontEnd is a pluggable module yet also consists of pluggable modules itself V L INGUIST The Linguist generates the SearchGraph that is used by the decoder during the search while at the same time hiding the complexities involved in generating this graph As is the case throughout Sphinx 4 the Linguist is a pluggable module allowing people to dynamically configure the system with different Linguist implementations A typical Linguist implementation constructs the SearchGraph using the language structure as represented by a given LanguageModel and the topological structure of the AcousticModel HMMs for the basic sound units used by the system The Linguist may also use a Dictionary typically a pronunciation lexicon to map words from the LanguageModel into sequences of AcousticModel elements When generating the SearchGraph the Linguist may also incorporate sub word units with contexts of arbitrary length if provided By allowing different implementations of the Linguist to be plugged in at runtime Sphinx 4 permits individuals to provide different configurations for different system and recognition requirements For instance a simple numerical digits recognition application might use a simple Linguist that keeps the search space entirely in memory On the other hand a dictation application with a 100K word vocabulary might use a sophisticated Linguist that keeps only a small portion of the potential search space in memory at a time The Linguist itself consists of three pluggable components the LanguageModel the Dictionary and the AcousticModel which are described in the following sections A LanguageModel The LanguageModel module of the Linguist provides word level language structure which can be represented by any number of pluggable implementations These implementations typically fall into one of two categories graph driven grammars and stochastic N Gram models The graph driven grammar represents a directed word graph where each node represents a single word and each arc represents the probability of a word transition taking place The stochastic N Gram models provide probabilities for words given the observation of the previous n 1 words SMLI TR2004 0811 c 2004 SUN MICROSYSTEMS INC 4 The Sphinx 4 LanguageModel implementations support a variety of formats including the following SimpleWordListGrammar defines a grammar based upon a list of words An optional parameter defines whether the grammar loops or not If the grammar does not loop then the grammar will be used for isolated word recognition If the grammar loops then it will be used to support trivial connected word recognition that is the equivalent of a unigram grammar with equal probabilities B Dictionary The Dictionary provides pronunications for words found in the LanguageModel The pronunciations break words into sequences of sub word units found in the AcousticModel The Dictionary interface also supports the classification of words and allows for a single word to be in multiple classes Sphinx 4 currently provides implementions of the Dictionary interface to support the CMU Pronouncing Dictionary 23 The various implementations optimize for usage patterns based on the size of the active vocabulary For example one implementation will load the entire vocabulary at system initialization time whereas another implementation will only obtain pronunciations on demand C AcousticModel The AcousticModel module provides a mapping between a unit of speech and an HMM that can be scored against incoming features provided by the FrontEnd As with other systems the mapping may also take contextual and word position information into account For example in the case of triphones the context represents the single phonemes to the left and right of the given phoneme and the word position represents whether the triphone is at the beginning middle or end of a word or is a word itself The contextual definition is not fixed by Sphinx 4 allowing for the definition of AcousticModels that contain allophones as well as AcousticModels whose contexts do not need to be adjacent to the unit Typically the Linguist breaks each word in the active vocabulary into a sequence of context dependent sub word units The Linguist then passes the units and their contexts to the AcousticModel retrieving the HMM graphs associated with those units It then uses these HMM graphs in conjunction with the LanguageModel to construct the SearchGraph Unlike most speech recognition systems which represent the HMM graphs as a fixed structure in memory the Sphinx 4 HMM is merely a directed graph of objects In this graph each node corresponds to an HMM state and each arc represents the probability of transitioning from one state to another in the HMM By representing the HMM as a directed graph of objects instead of a fixed structure an implementation of the AcousticModel can easily supply HMMs with different topologies For example the AcousticModel interfaces do not restrict the HMMs in terms of the number of states the number or transitions out of any state or the direction of a transition forward or backward Furthermore Sphinx 4 allows the number of states in an HMM to vary from one unit to another in the same AcousticModel Each HMM state is capable of producing a score from an observed feature The actual code for computing the score is done by the HMM state itself thus hiding its implementation from the rest of the system even permitting differing probability density functions to be used per HMM state The AcousticModel also allows sharing of various components at all levels That is the components that make up a particular HMM state such as Gaussian mixtures transition matrices and mixture weights can be shared by any of the HMM states to a very fine degree As with the rest of Sphinx 4 individuals can configure Sphinx 4 with different implementations of the AcousticModel based upon their needs Sphinx 4 currently provides a single AcousticModel implementation that is capable of loading and using acoustic models generated by the Sphinx 3 trainer D SearchGraph Even though Linguists may be implemented in very different ways and the topologies of the search spaces generated by these Linguists can vary greatly the search spaces are all represented as a SearchGraph Illustrated by example in Figure 3 the SearchGraph is the primary data structure used during the decoding process SMLI TR2004 0811 c 2004 SUN MICROSYSTEMS INC 5 Fig 3 Example SearchGraph The SearchGraph is a directed graph composed of optionally emitting SearchStates and SearchStateArcs with transition probabilities Each state in the graph can represent components from the LanguageModel words in rectangles Dictionary sub word units in dark circles or AcousticModel HMMs The graph is a directed graph in which each node called a SearchState represents either an emitting or a non emitting state Emitting states can be scored against incoming acoustic features while non emitting states are generally used to represent higher level linguistic constructs such as words and phonemes that are not directly scored against the incoming features The arcs between states represent the possible state transitions each of which has a probability representing the likelihood of transitioning along the arc The SearchGraph interface is purposely generic to allow for a wide range of implementation choices relieving the assumptions and hard wired constraints found in previous recognition systems In particular the Linguist places no inherent restrictions on the following SMLI TR2004 0811 c 2004 SUN MICROSYSTEMS INC 6 VI D ECODER The primary role of the Sphinx 4 Decoder block is to use Features from the FrontEnd in conjunction with the SearchGraph from the Linguist to generate Result hypotheses The Decoder block comprises a pluggable SearchManager and other supporting code that simplifies the decoding process for an application As such the most interesting component of the Decoder block is the SearchManager The Decoder merely tells the SearchManager to recognize a set of Feature frames At each step of the process the SearchManager creates a Result object that contains all the paths that have reached a final non emitting state To process the result Sphinx 4 also provides utilities capable of producing a lattice and confidence scores from the Result Unlike other systems however applications can modify the search space and the Result object in between steps permitting the application to become a partner in the recognition process Like the Linguist the SearchManager is not restricted to any particular implementation For example implementations of the SearchManager may perform search algorithms such as frame synchronous Viterbi A bi directional and so on Each SearchManager implementation uses a token passing algorithm as described by Young 24 A Sphinx 4 token is an object that is associated with a SearchState and contains the overall acoustic and language scores of the path at a given point a reference to the SearchState a reference to an input Feature frame and other relevant information The SearchState reference allows the SearchManager to relate a token to its state output distribution context dependent phonetic unit pronunciation word and grammar state Every partial hypothesis terminates in an active token As illustrated in Figure 1 implementations of a SearchManager may construct a set of active tokens in the form of an ActiveList at each time step though the use of an ActiveList is not required As it is a common technique however Sphinx 4 provides a sub framework to support SearchManagers composed of an ActiveList a Pruner and a Scorer The SearchManager sub framework generates ActiveLists from currently active tokens in the search trellis by pruning using a pluggable Pruner Applications can configure the Sphinx 4 implementations of the Pruner to perform both relative and absolute beam pruning The implementation of the Pruner is greatly simplifed by the garbage collector of the Java platform With garbage collection the Pruner can prune a complete path by merely removing the terminal token of the path from the ActiveList The act of removing the terminal token identifies the token and any unshared tokens for that path as unused allowing the garbage collector to reclaim the associated memory The SearchManager sub framework also communicates with the Scorer a pluggable state probability estimation module that provides state output density values on demand When the SearchManager requests a score for a given state at a given time the Scorer accesses the feature vector for that time and performs the mathematical operations to compute the score In the case of parallel decoding using parallel acoustic models the Scorer matches the acoustic model set to be used against the feature type The Scorer retains all information pertaining to the state output densities Thus the SearchManager need not know whether the scoring is done with continuous semi continuous or discrete HMMs Furthermore the probability density function of each HMM state is isolated in the same fashion Any heuristic algorithms incorporated into the scoring procedure for speeding it up can also be performed locally within the scorer In addition the scorer can take advantage of multiple CPUs if they are available The current Sphinx 4 implementation provides pluggable implementations of SearchManagers that support frame synchronous Viterbi 18 Bushderby 25 and parallel decoding 26 SMLI TR2004 0811 c 2004 SUN MICROSYSTEMS INC 7 WER RT Sphinx 3 3 Sphinx 4 Sphinx 3 3 Sphinx 4 1 CPU Sphinx 4 2 CPU TI46 11 words 1 217 0 168 0 14 0 03 0 02 TIDIGITS 11 words 0 661 0 549 0 16 0 07 0 05 AN4 79 words 1 300 1 192 0 38 0 25 0 20 RM1 1000 words 2 746 2 739 0 50 0 50 0 40 WSJ5K 5000 words 7 323 7 174 1 36 1 22 0 96 HUB 4 64000 words 18 845 18 878 3 06 4 40 3 80 TABLE I S PHINX 4 PERFORMANCE W ORD E RROR R ATE WER IS GIVEN IN PERCENT R EAL T IME RT SPEED IS THE RATIO OF UTTERANCE DURATION TO THE TIME TO DECODE THE UTTERANCE Test F OR BOTH A LOWER VALUE INDICATES BETTER PERFORMANCE D ATA GATHERED ON A D UAL CPU 1015M HZ U LTRA SPARC R III WITH 2G RAM Furthermore the modularity of Sphinx 4 also allows it to support a wide variety of tasks For example the various SearchManager implementations allow Sphinx 4 to efficiently support tasks that range from small vocabulary tasks such as TI461 28 and TIDIGITS2 29 to large vocabulary tasks such as HUB 4 30 As another example the various Linguist implementations allow Sphinx 4 to support different tasks such as traditional CFG based command and control applications in addition to applications that use stochastic language models The modular nature of Sphinx 4 was enabled primarily by the use of the Java programming language In particular the ability of the Java platform to load code at run time permits simple support for the pluggable framework and the Java programming language construct of interfaces permits separation of the framework design from the implementation The Java platform also provides Sphinx 4 with a number of other advantages 1 TI46 2 TIDIGITS refers to the NIST CD ROM Version of the Texas Instruments developed 46 Word Speaker Dependent Isolated Word Speech Database refers to the NIST CD ROM Version of the Texas Instruments developed Studio Quality Speaker Independent Connected Digit Corpus SMLI TR2004 0811 c 2004 SUN MICROSYSTEMS INC 8 the Sphinx 4 acoustic model design allows for very fine parameter tying We predict that taking advantage of these capabilities will greatly increase both the speed and accuracy of the decoder We have created a design for a Sphinx 4 acoustic model trainer that can produce acoustic models with these desirable characteristics 31 As with the Sphinx 4 framework the Sphinx 4 acoustic model trainer has been designed to be a modular pluggable system Such an undertaking however represents a significant effort As an interim step another area for experimentation is to create FrontEnd and AcousticModel implementations that support the models generated by the HTK system 1 We have also considered the architectural changes that would be needed to support segment based recognition frameworks such as the MIT SUMMIT speech recognizer 32 A cursory analysis indicates the modifications to the Sphinx 4 architecture would be minimal and would provide a platform to do meaningful comparisons between segemental and fixed frame size systems Finally the SearchManager provides fertile ground for implementing a variety of search approaches including A fast match bi directional and multiple pass algorithms IX C ONCLUSION After careful development of the Sphinx 4 framework we created a number of differing implementations for each module in the framework For example the FrontEnd implementations support MFCC PLP and LPC feature extraction the Linguist implementations support a variety of language models including CFGs FSTs and N Grams and the Decoder supports a variety of SearchManager implementations including traditional Viterbi Bushderby and parallel searches Using the ConfigurationManager the various implementations of the modules can be combined in various ways supporting our claim that we have developed a flexible pluggable framework Furthermore the framework is performing well both in speed and accuracy when compared to its predecessors The Sphinx 4 framework is already proving itself as being research ready easily supporting various work such as the parallel and Bushderby SearchManagers as well as a specialized Linguist that can apply unigram smear probabilities to lex trees We view this as only the very beginning however and expect Sphinx 4 to support future areas of core speech recognition research Finally the source code to Sphinx 4 is freely available under a BSD style license The license permits others to do academic and commercial research and to develop products without requiring any licensing fees More information is available at http cmusphinx sourceforge net sphinx4 ACKNOWLEDGMENTS The authors would like to thank Prof Richard Stern at CMU Robert Sproull at Sun Microsystems Laboratories and Joe Marks at MERL for making this team possible We also thank Sun Microsystems Laboratories and the current management for their continued support and collaborative research funds Rita Singh was sponsored by the Space and Naval Warfare Systems Center San Diego under Grant No N66001 99 1 8905 The content of this paper does not necessarily reflect the position or the policy of the U S Government and no official endorsement should be inferred R EFERENCES 1 S Young The HTK hidden Markov model toolkit Design and philosophy Cambridge University Engineering Department UK Tech Rep CUED FINFENG TR152 Sept 1994 2 N Deshmukh A Ganapathiraju J Hamaker J Picone and M Ordowski A public domain speech to text system in Proceedings of the 6th European Conference on Speech Communication and Technology vol 5 Budapest Hungary Sept 1999 pp SMLI TR2004 0811 c 2004 SUN MICROSYSTEMS INC 9 14 X Huang A Acero F Alleva M Hwang L Jiang and M Mahajan From SPHINX II to Whisper Making speech recognition usable in Automatic Speech and Speaker Recognition Advanced Topics C Lee F Soong and K Paliwal Eds Norwell MA Kluwer Academic Publishers 1996 15 S B Davis and P Mermelstein Comparison of parametric representations for monosyllable word recognition in continuously spoken sentences in IEEE Transactions on Acoustic Speech and Signal Processing vol 28 no 4 Aug 1980 16 H Hermansky Perceptual linear predictive PLP analysis of speech Journal of the Acoustical Society of America vol 87 no 4 pp 