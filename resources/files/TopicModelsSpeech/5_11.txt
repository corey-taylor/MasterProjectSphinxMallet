Proceedings of The National Conference On Undergraduate Research NCUR 2011 Ithaca College New York March 31 April 2 2011 Development of the Speech Capabilities of a Tour Guide Robot Fabian Okeke Computer Science Fisk University Nashville Tennessee 37208 USA Faculty Advisor 1Dr Wyatt Newman 1 Electrical Engineering and Computer Science Case Western Reserve University Cleveland Ohio 44106 USA Abstract The EECS Department at Case is developing a tour guide robot In addition to its localization and locomotion capabilities verbal communication with the robot will make interactively attractive Speech capability is being pursued in two parts speech synthesis and speech recognition Speech synthesis involves the conversion of words into vocal sounds For this development open source software Festival and Espeak text to speech TTS systems are being utilized together with VLC media player These speech synthesizers convert simple sentences and text files into wave files and these wave files are played and controlled using the VLC interface Speech production is implemented within the system as a network resource which allows for modular development and extensibility Upon receiving a network request to orate a specific script the speech service produces the desired output In continuing work speech recognition is being developed to enable commanding robot behaviors through spoken commands Speaker independent speech recognition is desired for which the Sphinx4 or PocketSphinx open source software is being used on the Ubuntu Linux Operating System The process involves conversion of continuous acoustical signals into words using recognition of phonemes Words are recognized using a grammar library which is manually populated with commands to be recognized by the robot An ongoing challenge will be how to expand this library while maintaining reliable recognition given that a larger database of words will contain more opportunities for audible confusion Through the use of open source software and network based modules this project is enabling interactive speech capability for a tour guide robot while providing a foundation for future growth of sophistication Keywords Text To Speech Synthesizer Independent Speech Recognizer Open Source 1 Introduction The EECS Department at Case is developing a tour guide robot In addition to its localization and locomotion capabilities verbal communication with the robot will make interactively attractive For effective communication between the robot and tourists the robot needs to talk and listen appropriately He also needs to process certain commands and carry out corresponding actions when faced with different scenarios For instance In a situation in which Roberto s pathway is blocked by tourists or any obstacles he quickly reacts with Please excuse me so I can move In order to implement all these functions this research work utilizes speech synthesizers in speaking to end users and speech recognizers in listening to them Although other non open source 1 1 Speech Synthesizer Speech Synthesis involves the conversion of words and text files into sounds and wave files respectively Frequency slicing is a recent technique applied in speech synthesis It involves the production of wave forms through the combination of one or more incomplete speech segments It can also be used in the production of incomplete speech segments which refers to missing frequency components in a frequency range If it produces incomplete frequencies then it is called Frequency Splicing Components FSC On the other hand complete speech segment contains all the desired frequency components and this can be used in creating Frequency Sliced Segment FSS 2 In this research Espeak and Festival speech synthesizers are utilized These synthesizers are selected amongst other existing speech tools because it is inexpensive and it properly integrates with the other libraries used in this research work The speech synthesizer converts written words or text files to sound files Festival Text To Speech TTS synthesizer receives text words from either a text file or from the Linux bash command line Then the received texts are broken down into identifiable dictionary words Based on the selected speaker s 1 2 Speech Recognizer A speech recognizer converts sound waves into words It is the direct opposite of a speech synthesizer Over the years speech recognition has changed through different techniques ranging from the use of Digital Filter DF Fast Fourier Transformer FFT Dynamic Time Warping DTW and the Hidden Markov Model HMM Recent research works have combined Mel Frequency Cepstrum Coefficient MFCC and DTW in order to improve the results of speech recognition3 For this project Sphinx4 speech recognizer is utilized Just like the speech synthesizer Sphinx 4 is selected from the list of numerous speech recognizers because it is free it works properly with the other tools for this project and it can be expanded based on need Sphinx 4 has its beauty in its modularity and plug ability Besides implementing continuous and non continuous large vocabulary vs smaller vocabulary an xml configuration file allows varied and dynamic behavior from the speech engine without a need for modifying the source code or recompiling 304 Figure 1 Sphinx 4 Framework Figure 1 above shows the architecture of the Sphinx 4 and its replaceable modules The speech engine of Sphinx 4 consists of 3 main modules the Front End the Decoder and the Linguist The Front End parameterizes input signals into a sequence of Features The Linguist generates the SearchGraph using a language structure and the topological structure of the AcousticModel4 The Acoustic Model consists of a set of Hidden Markov Models HMMs with one HMM per unit5 The Linguist may utilize a Dictionary to map words from the LanguageModel into sequences of Acoustic Model elements The ConfigurationManager deals with the structure of modules at run time while the SearchManager in the Decoder combines the FrontEnd and the SearchGraph from the Linguist to perform actual decoding The behavior of each of these modules can be individually configured in the xml configuration file The breakdown of these modules supports the performance of the Sphinx 4 which is a reconstruction and enhancement of other versions of recognizers including Sphinx 3 Any application incorporating Sphinx appears to go through 5 basic steps as in the Load in xml configuration file create Configuration Manager which interprets xml use lookup on Configuration Manager to create Recognizer object the speech engine and audio input data stream go into loop that is based on audio events where the Recognizer analyzes speech to return Results call Result methods to convert speech analysis into text strings or do more advanced operation 6 This research ensures that the returned texts from the 305 2 Methodology 2 1 Design The input device microphone collects a user s input sound and sends them to Sphinx4 PocketSphinx speech recognizer Then the speech recognizer interprets the input into words commands and selects a corresponding number mapped to each command Thereafter the new number is sent from the client side to the server side via network resourcing On receipt of the integer from client server sends confirmatory information back to client Then the received command is transferred from the server to a Mapper function The Mapper function relying on the Mapper module calls a database Figure 2 Architecture of Project The breakdown of the design into different modules gives way for easy expansion of the project For instance separating the code implementation into Client and Server side connection allows convenient modification and extension of the received input which occurs on the Client side and the implementation of the interpreted commands on the server side Hence one can adjust one network section without affecting the other In addition the use of a Mapper file makes the addition of more commands easy for even a non programmer In order to add more commands the yaml file which is similar to a text file can be edited and numbers with corresponding commands can be added Even though Festival could have been used in handling the returned spoken commands VLC provides a more convenient programming interface With VLC media player several sound output could be implemented and run using program threads 2 2 Algorithm Implementation The implementation of the algorithm for this project was written in two programming languages python and Java For speech recognition CMU Sphinx 4 can only be conveniently programmed in Java since the recognizer was implemented in Java On the other hand PocketSphinx is the equivalent of Sphinx 4 but in Python In addition Espeak speech synthesizer already comes installed with the Ubuntu Linux Operating System thus making the tools for the speech development readily available This choice of tools and programming languages were mainly based on research preference and better synchronization of all the tools used for this project 306 The codes and diagram below give a glimpse of the project implementation and workspace 2 2 1 mapper file 1 command_type say_string play_media hello there how are you priority 5 control_command stop 2 command_type say_wav play_media home fabiano Desktop VLC_NEW sound_files MJ Akon mp3 priority 6 control_command 3 command_type say_text play_media home fabiano Desktop VLC_NEW text_files MAE txt priority 8 control_command Figure 3 Section of Yaml File The mapper file shows a few commands and their corresponding numbers When the mapper function is called it loads the above yaml file and then returns a tuple of instructions of any corresponding number which is required Based on the priority of the returned tuple the tuple is sorted into a queue If a certain command with its given priority say 5 is running and another command with a higher priority say 3 is inserted into the queue then the command pauses and executes the most recent command with a higher priority In practical terms the robot could be talking about the history of a building assuming the priority of this command is 5 Then if a tourists stands in the robot s pathway while the robot is moving the excuse me please 2 2 2 python code implementation def say_text self text_file_path Read any given text file Must collect the pathway of the file and confirm it exists update the status of text_file_status if there is any given file path check given file path and confirm it is valid If valid assign it to self file_path for reuse later check_path find text_file_path print check_path 307 os system check_path self text_file_status True self file_path text_file_path self convert Figure 4 Python Function Connecting Mapper and Speech Modules Figure 4 is one of the python functions which also exist in the yaml file Depending on the interpreted results from the yaml file the say_text function or any other function could be returned as a tuple and sent to the Speech Module for appropriate execution For instance from Figure 3 if the number three returns its generated tuple then the say_text function is called This function collects the pathway of a text file verifies the availability of the file as shown in Figure 4 and then converts the file into a sound wave form which is controlled using VLC interface 2 2 3 VLC media interface The VLC media player library uses python bindings which are ctypes based7 The library consists of numerous functions that start with the creation of an Instance object With this object triggered events can be handled by the VLC media player at any time 2 2 4 java Sphinx 4 recognizer in action Figure 5 Workspace of Speech Recognizer Figure 5 shows the workspace of the speech recognizer and its elementary implementation of simple commands which are written on screen after the speaker says them At elementary stage words can be added to the grammar file for more recognition but as the vocabulary increases a vocabulary database would be required as opposed to individual addition of words 308 3 Discussion of Results Although satisfactory level of speech synthesis and recognition is yet to be attained due to the time frame of conducting the research work there is still room to attain optimum results in future work At the time of research the robot can talk about any area it tours it can also comfortably respond to simple instructions and read any text file assigned to it However the greatest challenge lies in the speech recognition as it is supposedly efficient irrespective of the accent of the tourists users speaking to the robot Unfortunately some people could speak to the robot and have their commands quickly interpreted while others could speak and have a delay in the breakdown and interpretation of phonemes Another challenge posed by the speech recognizer is the confusion of similar sounding words For instance keywords tall and call could be mixed up Consequently the commands tied to tall could be implemented for call In order to tackle the problem of speech analysis of everyone irrespective of his her accent users would be told keywords that can be used whenever their commands cannot be understood Tourists will also have the option of calling numbers to implement certain commands as opposed to saying the commands For example instead of tell me about the oldest Engineering laboratory the user would say a 4 Conclusion A speech system has been illustrated that optimally utilizes a combination of network connection a text to speech synthesizer a media player and speech recognition software on the Ubuntu Linux Operating System The principal advantage of the technique of speech development discussed in this research paper lies in the development of an efficient speech system based on open source software In this research the use of different modules gives room for future extension for larger projects For future work concentration will be on the expansion of the grammar library while concurrently reducing possible audible confusions in the speech recognizer 5 Acknowledgments The author would like to thank the Department of Electrical Engineering and Computer Science of Case Western Reserve University especially his advisor Dr Wyatt Newman for the opportunity to embark on an exciting research area Also the Case Western ACES summer program for an excellent summer 2010 research is highly appreciated Finally I appreciate my family for their support and encouraging words which always propel me to study and give my contributions in order to make the world a better place 6 References 1 Sjolander Kare and B J 2000 Wavesurfer An Open Source Speech Tool Proceedings of ICSLP vol 4 309 5 Evandro Gouvea et al 2002 Sphinx 4 for the JavaTM platform Architecture Notes http www speech cs cmu edu cmusphinx twiki Sphinx4 WebHome Architecture pdf 6 Voicerecog Sphinx 4 architecture 2006 http www xncroft com blog lyceum voicerecog 2006 07 05 sphinx 4 architecture 7 VLC Media python bindings 2011 http liris cnrs fr advene download python ctypes 310 