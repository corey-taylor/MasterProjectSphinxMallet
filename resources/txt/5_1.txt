A Framework for Integrating Heterogeneous Sporadic Knowledge Sources into Automatic Speech Recognition Stefan Ziegler Guillaume Gravier CNRS IRISA Campus de Beaulieu 35042 Rennes France firstname lastname irisa fr Abstract Heterogeneous knowledge sources that model speech only at certain time frames are difficult to incorporate into speech recognition given standard multimodal fusion techniques In this work we present a new framework for the integration of this sporadic knowledge into standard HMM based ASR In a first step each knowledge source is mapped onto a logarithmic score by using a sigmoid transfer function Theses scores are then combined with the standard acoustic models by weighted linear combination Speech recognition experiments with broad phonetic knowledge sources on a broadcast news transcription task show improved recognition results given knowledge that provides complementary information for the ASR system Index Terms multimodal fusion landmark driven ASR eventbased speech recognition 1 Introduction Multimedia data in the form of broadcasts podcasts as well as audio visual content present difficult challenges for state ofthe art hidden Markov model HMM based automatic speech recognition ASR since ASR systems are still sensitive towards unseen speaking styles and changes in acoustic conditions To improve acoustic modeling of HMM based ASR many studies advocate the incorporation of complementary knowledge sources into standard ASR to achieve improved recognition accuracy or robustness Examples of such complementary knowledge sources are phonetic models that aim at exploiting different features and modeling techniques motivated by phonological studies to build reliable and sometimes highly specialized detectors for phonetic classes 1 2 3 4 Another example is audio visual ASR where if available the visual modality is added to the existing acoustic information to benefit from the fact that acoustically similar speech classes might correspond to very different visual counterparts visemes that are reliable to detect 5 While it has often been argued that it is desirable for each knowledge source to rely on individual features and modeling techniques the common architecture of state of the art ASR has become a bottleneck for seamlessly integrating heterogeneous knowledge into speech recognition Consequently external knowledge sources often rely on rather homogeneous standard modeling techniques like frame based Gaussian mixture models that are integrated with conventional feature or decision fusion techniques inside the given architecture of HMM based ASR In this paper we present a new framework for integrating heterogeneous sporadic knowledge sources into HMM based ASR with the term sporadic referring to the fact that each knowledge is only defined at certain time frames often referred to as events e g 1 6 or landmarks e g 7 8 Indeed many acoustic or visual cues for phonetic events or visemes are naturally modeled as a sequence of discrete events rather than continous values which makes their integration into ASR very difficult given common multimodal fusion techniques In our framework integration of theses knowledge sources into standard HMM based ASR is performed in two steps First we map each knowledge source onto a logarithmic score using a sigmoid transfer function This allows the integration of knowledge sources of different scaling that appear asynchronously and do model arbitrary phonemic classes In a second step the obtained scores are combined with the acoustic scores of standard HMM based ASR using weighted linear combination These modified acoustic scores are integrated into the Viterbi decoding of the first pass of a large vocabulary ASR system In audio visual ASR continuous visual knowledge is often integrated into ASR via feature fusion i e concatenating audio and visual features to train refined acoustic models 9 This approach is also used for the integration of a burst onset landmark detector in 2 Decision fusion at the frame level using GMMs and HMMs by weighted linear combination of loglikelihood scores is used for integration of phonetic information in 10 and for visual information in 11 Phonetic knowledge is also integrated into ASR during the rescoring step of multipass ASR 3 7 Landmark based phonetic models have been used inside alternative probabilistic ASR frameworks 12 and in 1 statistical post processing of sporadic phonetic landmarks resulted in improved detection accuracy In the following section we will present our framework in detail before presenting speech recognition experiments using broad phonetic knowledge sources The paper will conclude with an outlook on future work 2 Integration of sporadic knowledge into ASR Given a speech utterance with t frames we consider a sporadic knowledge source k to be a function xk t with xk t being defined only for nk frames Txk t1 tnk Each source is the result of an external system specialized in detecting a given set of phonemes Sk which is a subset of the complete set of phonemes including non speech symbols P with Sk P To integrate this knowledge into triphone based ASR systems the phonemes in Sk have to be mapped to the corresponding states Ik which is equally a subset of the complete search space I see Figure 2 While the range of xk t is arbitrary for each source k for example one source could provide a probability from 0 to 1 while another source might correspond to a score in the range from to or to 0 we assume a clear correlation between xk t and Sk Assuming positive correlation low values for xk t are supposed to signal poor confidence in 37 Proceedings of the First Workshop on Speech Language and Audio in Multimedia SLAM Marseille France August 22 23 2013 the presence of Sk at t while high values have a very low error rate with a more or less sharp transition in between To illustrate such external knowledge sources we use the example of integrating phonetic landmark detectors into HMMbased ASR Landmark detection usually consists of two steps see for example 13 First the system detects potential locations for speech events landmarks before acoustic cues in vicinity of these landmarks are evaluated to estimate the probability of one or several phonetic classes for each landmark For example vowels can be detected by local maxima in the first formant frequency and evaluation of additional features around this landmark can specify the type of vowel An additional detector might provide landmarks signaling the presence of plosives by detecting abrupt changes in the signal and studying several cues like voice onset time or energy of the burst around this point see for example 14 It is obvious while the detection of vowels and plosives can be highly specialized for each phonetic class both classes are only defined at very specific locations Txk Furthermore the landmarks for vowels and plosives will be attached with a confidence estimate xk t that cannot be compared with each other since each class uses different classification algorithms and features With x t not being defined for most t sporadic knowledge can avoid to model parts of speech with high uncertainty about the acoustic content which is a major advantage compared to HMM based acoustic modeling While heterogeneity i e the fact that the ranges of each xk t are very different from each other could be overcome by normalization the sporadic nature of knowledge sources makes common fusion at the feature or decision level not feasible any more since k knowledge sources cannot be mapped onto a k dimensional vector at each frame t see Figure 3 In the following we present a general framework for the integration of k knowledge sources into the Viterbi decoding of a HMM based ASR system Given k sources xk t two steps are necessary from raw knowledge to knowledge driven ASR First we map each source xk onto a log likelihood score log sk given a sigmoid transfer function which parameters are estimated using cross entropy as the objective function In the second step these knowledge sources are integrated into the ASR system using a weighted linear combination of the obtained scores log sk and the acoustic scores of the ASR system 2 1 Weighted linear combination of k knowledge sources Given k knowledge sources our goal is to modify the acoustic score s i t for state i I at frame t according to weighted linear combination of the log likelihoods of k knowledge sources log sk i t and the unweighted log likelihood of the acoustic model log sasr i t given the weights wk log s i t log sasr i t X k xk t t log sk xk log sk t t Figure 1 Mapping a sporadic knowledge source xk t onto log sk t 2 2 Mapping of detection functions onto knowledge scores Intuitively log sk t should maximize the scores added to the correct path i e the scores added to frames t where the correct phoneme actually is a member of Sk but minimize the error it will introduce into the system by enhancing the wrong path Therefore our mapping function should result in log sk t 0 for low values of xk t but grow according to the confidence that higher values of xk will correctly indicate Sk This desired behavior can be obtained by a sigmoid function with log sk t k t T xk 1 exp k xk t k 2 k determines the steepness of the slope of the sigmoid k shifts the sigmoid to its optimal working point and k is a scaling factor For example if a knowledge source k provides a very reliable knowledge above a certain score k k will be a high value reflecting the confidence in the correctness of log sk t and a high k changes the transfer function from a smooth transition to a step function like behavior Equation 2 maps noisy unreliable values onto values very close to zero and rounding those values to a limited precision results in log sk t 0 Since log sk t 0 for all t Txk log sk t is effectively a sparse vector and we refer to its non zero frames as Tsk To find the optimal k k and k we maximize the crossentropy cce t between log sk t and the correct solution yk t at each frame cce t yk t log pk t log 1 pk t 1 yk t 3 Nk 1 Nk 0 wk log sk i t 1 With log sk i t 0 and wk 0 each source k enhances states i Ik that are associated with the phonemes in set Sk see Figure 2 Evidently log sk i t 0 for all states i Ik and for all frames t for which the source k is not defined with t Txk All states i Ik share the same likelihood score log sk i t to which we will refer to as log sk t The next section describes how to map xk t onto log sk t for each source before we discuss determining wk yk t is a binary vector with yk t 1 if Sk is correct at frame t and yk t 0 if not yk t is derived from the forced alignment of the correct utterance using our baseline ASR system pk t reflects the probability that knowledge source k is present at frame t Since some knowledge sources might have a skewed distribution we normalize pk t by the number of frames Nk 1 that are in Txk for which yk t 1 and respectively Nk 0 for which yk t 0 38 Proceedings of the First Workshop on Speech Language and Audio in Multimedia SLAM Marseille France August 22 23 2013 i t log s i t log sasr i t wk log sk i t k alignment of the n th hypothesis contained in the n best output of the ASR system By maximizing the MMI the correct hypothesis will become more likely while at the same time the competing hypothesis that do not correspond to the correct path at frame t will become less likely In this work we use only the best hypothesis as a competing alternative to the correct path so that n 1 which turns the MMI criterion into corrective training see 15 The optimization problem consists then in finding the T weights wk that maximize cmmi t over all frames in T k Tsk X Fmmi w u u log s cmmi t 8 tT Figure 2 Integration of knowledge into the speech decoding Arrows correspond to the transition probabilities while the nodes represent the acoustic scores log s i t The modified computation of log s i t is displayed for one node highlighted in grey 3 Experiments The corpus used in the experiments corresponds to radio broadcast news in the French language from the ESTER2 campaign 16 The ESTER2 dataset contains broadcast shows with speech in studio environments RFI but also difficult tasks like debates Inter or speech with strong accents radio TVME and radio Africa 1 Since we need the correct hypothesis to generate the correct state sequences u t and the aligned nbest recognition hypothesis u n t we discard every sentence containing out of vocabulary words during training and testing During testing this allows us to assure that finding the correct path by modifying the acoustic scores during the decoding is not prevented by missing vocabulary Additionally we discard all telephone speech from the dataset The estimation of the parameters k k k and wk are conducted on the ESTER2 development set using only broadcasts shorter than 20 minutes while final speech recognition experiments are conducted on the full ESTER2 test set The speech recognizer used in this paper is a two pass system trained on the ESTER1 and ESTER2 training data The first pass uses word internal triphones with 32 Gaussians per state and a trigram language model The second pass relies on 4 grams and cross word triphone models In this paper we integrate knowledge only in the first pass of our ASR system to generate improved word graphs for rescoring 3 1 Phonetic knowledge sources and baseline ASR system In the experiments we use broad phonetic classes BPCs as knowledge sources obtained from the Gaussian mixture models of a Mel frequency cepstral coefficients based monophone GMM classifier We derive 6 detection functions xk t for the BPCs vowels nasals approximants fricatives plosives and a non speech class Each BPC at frame t is first scored with the maximum score among all phonemes of this BPC before we perform normalization at each frame t by taking the logarithmic sum of exponentials for each source k to obtain 6 continuous detection functions After smoothing we convert these 6 functions into k 6 sporadic knowledge sources xk t by simple picking the local maxima for each detection function see Figure 3 Since the monophone models were trained on the same training data like our acoustic models it is unlikely that they actually will provide complementary information to the ASR system To experiment with more informative knowledge sources we additionally create oracle knowledge by adding a bias to the correct BPC at each frame t before performing normalization We refer to this knowledge sources as BPC oracle bias with bias being the scalar added to the correct BPC While this knowledge does not represent homogeneous knowledge in the sense that it incorporates different modeling and training frameworks we discuss the influence of multiplicative and additive scaling of Given the log likelihood scores of two complementary classes sk and sk we use the softmax function to estimate pk t according to p k t exp log sk t exp log sk t exp log sk t 4 As a consequence of the facts that all knowledge sources might model only a subset of P and sporadic knowledge results in asynchronous landmarks there is no score log sk t estimating the absence of knowledge source k at frame t Consequently this anti score log sk t always equals 0 log sk t 0 t 5 The final optimization problem consists in finding the parameters k k and k that maximize cce t for all frames of the training data X Fce k k k k xk yk cce t 6 tTxk 2 3 Estimation of the combination weights While the optimized knowledge sources log sk t might achieve low error rates according to Equation 6 it has yet to be determined if this source represents complementary knowledge to the acoustic models of the ASR system Therefore we use discriminative training to determine the weight wk for each source k that adjusts the contribution of source k to the overall acoustic score according to Equation 1 Estimating the weights wk of a linear combination of loglikelihoods is a well studied problem and several discrimination criteria have been proposed in the literature 15 11 10 In this paper we use the frame based maximum mutual information MMI between correct alignment and n competing hypothesis according to X cmmi t log s u t t log exp log s un t 7 n u t is the state sequence obtained by force aligning the correct solution of an utterance while u n t corresponds to the 39 Proceedings of the First Workshop on Speech Language and Audio in Multimedia SLAM Marseille France August 22 23 2013 Table 1 Word error rates of 4 different broad phonetic knowledge sources and the baseline ASR system on the ESTER2 development and test set each xk t in section 3 5 3 2 Optimization Given k knowledge sources xk t we have to optimize two objective functions to obtain the parameters k k and k for each knowledge source individually and the weights wk jointly We use L BFGS B minimization implemented in pythons scipy library for both objective functions with the constraints k 0 and k 0 for Equation 6 and wk 0 for Equation 8 The gradients of the objective functions are in both cases calculated using the symbolic differentiation implemented in the Theano package 17 For both objective functions we could achieve fast convergence by carefully choosing initial values for both optimization problems The scaling factor k should be proportional to the variance of xk t while the median of xk t is a good starting point for k For Equation 8 we started with the same value wk for all knowledge sources k by choosing the uniform weight which maximized Equation 8 This lead to Equation 6 needing about 20 iterations to converge while Equation 8 converged already after very few iterations Though we maximized the weights wk globally instead of using gradient descent we did not observe problems concerning convergence or overfitting 3 3 Speech Recognition Experiments After optimizing the mapping from xk t to log sk t for all sources k and estimating the weights wk on the development set speech recognition experiments were performed for BPC 0 BPC oracle 2 BPC oracle 3 and BPC oracle 4 Table 1 shows the word error rates WER on the ESTER2 development and test set along with the WER of the baseline As expected BPC0 did not provide any new information for the ASR system and obtained wk 0 for all BPCs except for the non speech class Consequently this led to no improvement in WER For the oracle BPCs the WER decreases with increasing the bias of the knowledge source For all cases the improvement on the development set is higher than on the test set as often observed in discriminative training 3 4 Evaluation of knowledge sources Table 2 displays two criteria evaluating the quality of xk t and log sk t for the BPCs of three different experiments AU C area under the curve is a performance measurement derived from the ROC curve receiver operator characteristic and equal to the probability that a classifier will rank a randomly selected true BPC higher than a randomly selected false BPC We use the AU C to give an indication of the quality of the raw knowledge source xk t Additionally for every knowledge source k we calculate a misclassification cost MI related to the mutual information criterion MMI in Equation 7 by calculating the av vow 0 nas 0 app 0 plo 0 fr knowledge baseline BPC 0 BPC oracle 2 BPC oracle 3 BPC oracle 4 WER dev 28 0 28 0 27 7 27 4 26 8 WER test 31 8 31 8 31 6 31 3 31 0 0 wav 0 log sk score 0 t vow nas app plo fr Figure 3 Spectrogram of the French word Bonjour uttered at the beginning of a broadcast show followed by six sporadic broad phonetic knowledge sources xk t BPC oracle2 including non speech and the obtained log likelihoods log sk t at the bottom All xk t are normalized so that 0 represents the maximum value The correct sequence of BPCs is marked in grey erage score added at each frame Tsk with weighting every correct frame by 1 and every incorrect frame by 1 This results in a negative value if a knowledge source introduces more errors into the decoding than it enhances the correct path 1 X 2yk t 1 log sk t T tT M I k T 9 T corresponds to the cardinality of the frames T used to calculate M I k T Both measures are shown on all available frames Txk for AU C and Tsk for M I Additionally they are calculated only on those frames Tk where the correct BPC of the true alignment u t differs from the BPC in u n t Since the acoustic score of the standard ASR system is not modified see Equation 1 we expect an improvement of the WER only if a knowledge source is able to correctly enhance most of the frames that are not already correctly aligned in the best recognition hypothesis Indeed it can be seen that BPC0 while performing relatively well on all frames T has a below random AU C with AU C 0 5 for all BPCs except silence for T For those BPCs M I is negative which means these knowledge sources make it less likely for the decoder to find the correct path at frames T Consequently discriminative training resulted in wk 0 for all BPCs except silence to prevent the ASR system from degrading In general evaluating the errors of a knowledge source without taking the output of the speech recognizer into account might be misleading Only 40 Proceedings of the First Workshop on Speech Language and Audio in Multimedia SLAM Marseille France August 22 23 2013 BPCs BPC 0 BPC oracle AUC MI AUC MI AUC MI 2 BPC oracle 4 T Tk Tk Tk Tk Tk Tk Tk Tk Tk Tk Tk Tk 0 84 0 41 0 9 0 0 94 0 67 1 9 0 7 0 98 0 87 3 0 1 9 vow 0 90 0 43 0 6 0 1 0 96 0 63 1 0 0 4 0 99 0 81 1 7 1 3 nas 0 95 0 37 2 1 0 5 0 98 0 59 3 3 0 5 0 99 0 80 4 6 2 1 plo 0 93 0 35 1 7 0 5 0 98 0 61 3 0 0 6 0 99 0 83 4 2 2 1 fri 0 96 0 34 2 5 0 8 0 99 0 53 3 1 0 2 0 99 0 73 3 6 0 8 app 0 83 0 46 0 8 0 1 0 93 0 70 1 9 0 6 0 98 0 88 3 2 2 0 knowledge baseline BPC oracle 2 vow nas pl BPC oracle 3 vow nas pl BPC oracle 4 vow nas pl WER dev 28 0 27 6 27 5 27 3 WER test 31 8 31 8 31 7 31 5 Table 3 Word error rates of 3 different broad phonetic knowledge sources using only the BPCs vowels nasals and plosives each time curate to be effective Obviously efforts have to be made to research on existing and new knowledge sources that provide sufficiently accurate landmarks Furthermore it is desirable to experiment with additional feature systems like distinctive features or visual features like visemes Objective functions While the sigmoid transfer function in connection with the cross entropy criterion in Equation 6 as well as the MMI criterion for discriminative training provided good results one might consider additional transfer functions and training criteria State dependent weights and context dependency One disadvantage of the presented approach is the fact that it does not include state or phoneme dependent weights wi k for Equation 1 Enhancing states that are not in Ik for a knowledge source k might help to reduce the error introduced into the decoding since this might take into account common phonetic confusions like it is the case for vowels and approximants Additionally the speech recognition system could be modified to accommodate for a weight wasr that scales log sasr i t in Equation 1 to improve the discriminative training criterion Given phonetic landmarks as employed in this paper the probability of a speech class Sk at t depends on the context i e its preceding and subsequent landmarks To address this context dependency landmarks xk t could be rescored by additional models that are trained on landmark sequences like it has been proposed in 1 Integration into multi pass ASR In the current implementation we only implemented knowledge driven ASR in the first pass of our speech recognizer To fully benefit from heterogeneous knowledge sources integration into rescoring steps of multi pass ASR systems is desirable Table 2 AU C for xk t and M I for log sk t given different knowledge sources and their broad phonetic classes silence and non speech vowels nasals plosives fricatives and approximants Tk corresponds either to Txk for AU C or Tsk for M I when knowledge sources xk t achieve above random AU C on T M I tends to turn positive and the source contributes to improving the WER as it is the case for BPC oracle 2 and BPC oracle 4 3 5 Heterogeneous knowledge The previous broad phonetic knowledge sources were obtained using homogeneous monophone GMM classifier and thus did not represent a collection of heterogeneous knowledge sources Assuming heterogeneous knowledge will change xk t into xk t by multiplicative and additive scaling with xk t ak xk t bk it is evident that given our proposed sigmoid transfer function this scaling can be reversed by estimating the corresponding k and k To avoid the problem of finding an individual initialization for k and k to optimize objective function 6 for each knowledge source we recommend to perform a simple normalization for example mean and variance normalization for each knowledge source xk t All of our experiments showed that given proper initialization for k and k log sk t and consequently M I k T was similar for different multiplicative and additive scaling factors One advantage of our presented framework is the fact that it is able to deal with selected knowledge sources that may not cover the complete set of phonemes P This allows to design individual detectors for each phonemic group Sk without forcing to model the whole set P Table 3 shows the same speech recognition experiments as in section 3 3 but with the reduced set of BPCs vowels nasals and plosives It can be seen that the WER increases compared to using the complete range of BPCs and the overall impact of the provided knowledge sources is reduced This is expected since the broader the external knowledge sources become the less impact they will have onto the speech decoding even if a knowledge source inserts only few errors into the decoding 5 Conclusions The presented framework focused on the integration of heterogeneous and sporadic knowledge sources into HMM based ASR It allows the use of individual training and detection algorithms for each knowledge source that can be developed independently from each other Furthermore it accounts for event or landmark based models of speech and does not require the re training of existing acoustic models We used a transfer function to map each knowledge source onto a logarithmic score before the obtained values were combined with the acoustic scores by weighted linear combination While the knowledge sources that improved the WER in this paper corresponded to oracle knowledge we conclude from our experiments that landmarks which achieve an above random detection performance on frames where the ASR system aligns the wrong path are likely to improve the recognition performance of HMM based ASR systems 4 Future Work Our presented framework showed promising results given different kinds of broad phonetic knowledge sources Before concluding the paper we want to point out several directions for future research Knowledge sources Our experiments showed while the integration of rather broad speech landmarks into HMM based ASR improves the recognition these landmarks need to be ac 41 Proceedings of the First Workshop on Speech Language and Audio in Multimedia SLAM Marseille France August 22 23 2013 6 References 1 A Jansen and P Niyogi Point process models for event based speech recognition Speech Communication vol 51 no 12 pp 42 Proceedings of the First Workshop on Speech Language and Audio in Multimedia SLAM Marseille France August 22 23 2013 