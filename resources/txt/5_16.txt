IEEE TRANSACTIONS ON AUDIO SPEECH AND LANGUAGE PROCESSING VOL 18 NO 6 AUGUST 2010 1539 Statistical Transformation of Language and Pronunciation Models for Spontaneous Speech Recognition Yuya Akita Member IEEE and Tatsuya Kawahara Senior Member IEEE Abstract We propose a novel approach based on a statistical transformation framework for language and pronunciation modeling of spontaneous speech Since it is not practical to train a spoken style model using numerous spoken transcripts the proposed approach generates a spoken style model by transforming an orthographic model trained with document archives such as the minutes of meetings and the proceedings of lectures The transformation is based on a statistical model estimated using a small amount of a parallel corpus which consists of faithful transcripts aligned with their orthographic documents Patterns of transformation such as substitution deletion and insertion of words are extracted with their word and part of speech POS contexts and transformation probabilities are estimated based on occurrence statistics in a parallel aligned corpus For pronunciation modeling subword based mapping between baseforms and surface forms is extracted with their occurrence counts then a set of rewrite rules with their probabilities are derived as a transformation model Spoken style language and pronunciation surface forms models can be predicted by applying these transformation patterns to a document style language model and baseforms in a lexicon respectively The transformed models significantly reduced perplexity and word error rates WERs in a task of transcribing congressional meetings even though the domains and topics were different from the parallel corpus This result demonstrates the generality and portability of the proposed framework Index Terms Automatic speech recognition ASR language model LM pronunciation model spontaneous speech statistical transformation I INTRODUCTION HE targets of large vocabulary continuous speech recognition LVCSR research have been extended in recent years to spontaneous speech such as telephone conversations lectures and meetings Large corpora of conversational telephone speech CTS such as Switchboard and Fisher corpora were collected and a number of LVCSR techniques have been developed with these corpora 1 2 The NIST Rich Transcription RT project has dealt with conversational speech recognition of meetings 3 Such multiparty meetings have also been T Manuscript received March 31 2009 revised October 23 2009 First published November 24 2009 current version published July 14 2010 This work was supported in part by the Strategic Information and Communications R D Promotion Program SCOPE Ministry of Internal Affairs and Communications Japan The associate editor coordinating the review of this manuscript and approving it for publication was Prof Haizhou Li The authors are with the Academic Center for Computing and Media Studies Kyoto University Kyoto 606 8501 Japan e mail yuya media kyoto u ac jp kawahara i kyoto u ac jp Digital Object Identifier 10 1109 TASL 2009 2037400 investigated by the AMI AMIDA project conducted by European research institutes 4 A number of speech and linguistic studies for lectures have been conducted using the Corpus of Spontaneous Japanese CSJ 5 which is a collection of academic lectures and public speeches Oral presentations and seminars have also been recorded by European projects such as the TED corpus 6 and the CHIL project 7 The LVCSR of classroom lectures has also been tackled mainly by universities 8 9 Speeches made at public gatherings such as in parliaments and courts are yet another target of LVCSR 1558 7916 26 1540 IEEE TRANSACTIONS ON AUDIO SPEECH AND LANGUAGE PROCESSING VOL 18 NO 6 AUGUST 2010 Fig 1 Concept underlying proposed statistical transformation In this paper we propose a novel approach to transform the language and pronunciation models to better model spontaneous speech in which the statistical characteristics of spontaneous speech are modeled separately from task dependent characteristics Large document archives such as those of meeting minutes and lecture proceedings are generally easy to access Although these archives are expected to match the target domain of LVCSR they do not have spoken style characteristics Spokenstyle models can be obtained from such large archives by modeling general transformations between orthographic document and spoken styles This transformation can be applied to various spontaneous speech recognition tasks because of the task independent framework Another advantage of the proposed approach is that since the transformation models are much smaller than conventional language and pronunciation models they can be trained with a smaller amount of training data This paper is organized as follows The basic concept underlying the proposed transformation framework is described in Section II Then the actual methods of transforming the language and pronunciation models are fully explained in Sections III and IV Section V describes typical characteristics of spontaneous Japanese which are modeled with the proposed approach The approach is evaluated for LVCSR with real data from congressional meetings Our experiments and the results are discussed in Section VI Section VII concludes the paper II BASIC CONCEPT UNDERLYING STATISTICAL TRANSFORMATION The basic idea behind the proposed transformation framework is illustrated in Fig 1 Spoken utterances in the conventional documentation process are transcribed once into a verbatim transcript and then formatted as a document When considering the formatting process as a translation from to an LVCSR system is followed by a statistical machine translation SMT 15 system to automatically produce these are documents Here a large number of spoken transcripts necessary to train the LVCSR system however faithful transcripts are expensive and the size of transcripts is actually limited Therefore direct estimates of the language and pronunciation models are virtually impossible with such small transcripts In contrast formatted documents such as the minutes of meetings which are manually edited are archived on a large scale These archives are often recorded in electronic form and are easily available Consequently the key idea behind the prointo language and pronunposed framework is to transform ciation models for spontaneous speech recognition by inverting the formatting process This inversion is modeled as a transformation model using together with corresponding formatted texts transcripts called a parallel corpus hereafter The transformation model for language model predicts N gram entries and estimates their occurrence statistics from document archives The transformation model for pronunciation model generates real pronunciation surface form entries from the orthodox pronunciation baseform of words found in the documents Pronunciation probabilities are also predicted and assigned to all pronunciation entries by the model The correspondences between spontaneous speech phenomena and orthographic expressions are solely targeted in both cases and the correspondences are extracted in a more generalized form than word level mappings Consequently the framework is expected to model transformation effectively and efficiently using a small amount of training data Both transformations are described in detail in the following sections III STATISTICAL TRANSFORMATION OF LANGUAGE MODEL We address the statistical transformation of the language model based on the framework described above The simulation and generation of spoken text from written or formal text have previously been proposed as an alternative to the baseline mixture based method mentioned in Section I For example Schramm et al 16 proposed generating a simulated spoken style text by randomly inserting fillers into written style text Petrik and Kubin 17 proposed restoring a literal transcript from non literal documents by using speech recognition and phonetic matching However predicting a verbatim transcript from a formatted text is not usually deterministic for example insertion of fillers is arbitrary though not random The reliability of N gram statistics was not always guaranteed in these approaches As the purpose of transformation for LVCSR is to build a spoken style language model and not to obtain a text itself it is more straightforward to estimate the language model statistics directly rather than producing a text Hori et al 18 proposed using a weighted finite state transducer WFST to transform a language model However linguistic expressions transformed into the spoken style were mostly handcrafted and variations and statistics were not well represented We extract the characteristics of the spoken style automatically from a corpus with a sufficient number of reliable statistics A Basic Formulation The concept underlying the proposed statistical transformation of the language model is illustrated in Fig 2 It is based on the framework of statistical machine translation 15 where a sentence of the target language is generated from a sentence of the source language which maximizes the posterior probusing Bayes rule ability 1 is usually computed with a translation model We consider document style and spoken style languages as different languages and denote the former as and the latter as AKITA AND KAWAHARA STATISTICAL TRANSFORMATION OF LANGUAGE AND PRONUNCIATION MODELS FOR SPONTANEOUS SPEECH RECOGNITION 1541 TABLE I MAJOR DIFFERENCES BETWEEN SPONTANEOUS SPEECH AND DOCUMENT STYLE TEXT Fig 2 Flow of language model transformation to generate transformation patterns and included in and to estimate probabilities In this paper we consider three types of transformation insertion deletion and substitution Suppose a filler ah is inserted in the middle of I think this is as shown in Fig 2 the words think and this are regarded as contexts and transformation think this and think ah this is modeled as Similarly deletion of a particle for from to wait for him now wait for him and wait him is expressed with and substitution of words am not to the colloquial expression ain t in today I am not fine because is modeled as I am not fine and I ain t fine Then N gram entries such as think ah think ah this and ah this are generated with input think this or think this where means any word If context words of the input N gram entries are not sufficient to provide transformed N gram entries for example ah this after insertion of ah in generating a trigram think this necessary context words are added Thus 3 is revised as follows 4 We can estimate spoken language model 1 by rewriting In case that can be generated from multiple entries the resulting occurrence count is a sum of counts estimated from respective by 4 2 5 The conditional probabilities and i e the transformation model can be estimated using a parallel corpus of faithful transcripts and corresponding document style texts When we assume N gram language model for both and actual estimation is carried out over N gram entries and their statistics because N gram probabilities are basically proportional to corresponding N gram statistics Thus 3 is derived from 2 to express an occurrence count of a spoken style N gram entry using that of the corresponding document style N gram entry found in an input corpus 3 where denotes the occurrence count of N gram entries When we further limit contextual information for and these probabilities are actually calculated as and for every pair of a spoken style word and a document style word sequence that are sequence found in the parallel aligned corpus The possibility of transformation depends on the context of the target spoken style expression therefore word contexts neighboring words are This context dependent model improves precision but encounters the problem of data sparseness because the parallel corpus is usually small To mitigate this problem we present three models based on back off linear interpolation and maximum entropy ME schemes which take into consideration part of speech POS information B Probabilities to be Estimated The language model of spontaneous speech is estimated within the above framework Types of transformation can be classified into three categories viz insertion deletion and substitution as listed in Table I We estimated conditional and for these cases Note probabilities that a detailed analysis of differences between spoken and orthographic Japanese is described in Section V A One of these three types is the insertion of words especially fillers Fillers are often observed at the beginning or the end of utterances and accompanied by a pause However their occurrence is not limited to these points and the frequency depends on actual filler words and contexts Hence insertion probability 1542 IEEE TRANSACTIONS ON AUDIO SPEECH AND LANGUAGE PROCESSING VOL 18 NO 6 AUGUST 2010 must be estimated In contrast deletion probability is always one for fillers since fillers must be removed from transcripts for documentation The second type is the deletion of words such as particles Not all particles are deleted in utterances and particles cannot be inserted at all possible points when transforming a transcript and into a document style text Thus both must be estimated The third type is substitution of colloquial words and phrases Similar to the first case not all possible words are actually substituted however observed colloquial expressions must always be corrected in document style texts Therefore should be estimated while is set to one C Training of Transformation Model The basic word based transformation model is directly trained using the occurrence counts of word sequences In a training corpus spoken and document style word sequences are annotated and aligned beforehand Then and the statistics occurrence counts for document style word and those for corresponding spoken style sequence are calculated using this parallel word sequence aligned corpus Then word based transformation probabilities are estimated as follows 6 For reliability of probabilities and computational saving we whose count cut off transformation patterns is smaller than or equal to or probability is smaller than However the problem of data sparseness arises with this basic model We introduced a transformation model based on POS tags to improve coverage and estimation accuracy A POS tag is assigned to every contextual word by using a morphological analyzer ChaSen 19 We use top level categories of POS tags such as verb adjective and adverb except that nouns and particles are classified into subcategories such as general noun proper noun and pronoun The transformation probabilfor POS based patterns e g VERB ities VERB ah PRONOUN are estimated in PRONOUN and the same way as defined in 6 The same thresholds and are applied to counts and probabilities of POS based patterns and are Conditional probabilities also estimated in the same manner D Back Off Scheme The word based and POS based transformation models can be applied to the N gram entries of a document style language model using 4 A back off scheme is used as the simplest way of combining word based and POS based models exists 7 where is a pattern made from by changing its context words to corresponding POS tags Each word based pattern if exists else if POS in this scheme such as think this think ah this is first applied to N gram entries in turn and transformation is carried out with when the pattern matches If it does not match a POS based pattern such as VERB PRONOUN VERB ah PRONOUN is applied When the POS based pattern matches the POS contexts of a transformed entry are replaced with original context words such as think and this to produce a new N gram entry Unlike standard back off N gram modeling we in this scheme bedo not use back off weights to is small in most cases and therefore back off cause weights tend to be almost one E Linear Interpolation Scheme We introduce a scheme of linear interpolation of the two models as an alternative to the back off method The weighted sum of the word based and POS based probabilities is used as the transformation probability in this scheme and transformation is conducted if either the word based or POS based pattern matches an original N gram entry 8 F Maximum Entropy Scheme The word based and POS based models in the above schemes are first separately estimated and then combined We introduce the maximum entropy ME scheme 20 to better count the lexical and POS information in a more integrated manner A conis determined by ditional probability 9 where is a feature function is a feature weight and is a normalization factor We used the preceding and following words and their POS tags as features for ME The ME model is applied to every N gram entry of the document style model and a spoken style N gram is generated if the transformation probability is larger than a threshold G Generation of N Gram Entries and Language Model For every input word sequence matching with every transis performed For all matched patterns formation pattern spoken style word sequence is generated from which corresponds to the matched pattern The occurrence count of is then calculated in real numbers based on the transformation probabilities which are defined in either of back off interpolation and ME schemes as described above Then statistics of N gram entries are calculated over the generated word sequences Fractions of N gram occurrence counts are finally rounded off and resulting integer counts are used to train a language model in a standard manner There are a large number of N gram entries whose count is less than one and these entries are discarded in this process Although rounding errors are inevitable here their effect is empirically insignificant and this process leads to memory efficiency and compatibility with existing toolkits AKITA AND KAWAHARA STATISTICAL TRANSFORMATION OF LANGUAGE AND PRONUNCIATION MODELS FOR SPONTANEOUS SPEECH RECOGNITION 1543 IV STATISTICAL TRANSFORMATION OF PRONUNCIATION MODEL Next we will describe the transformation of the pronunciation model The design of a pronunciation lexicon was conventionally an empirical issue Manual editing of lexicons 21 is however extremely costly and not practical for LVCSR Therefore various frameworks of pronunciation modeling have been proposed to automatically generate a lexicon Previous studies include the knowledge based approach such as the application of phonological rules However this approach does not provide the probabilities of the rules which are necessary to suppress false matching caused by increased numbers of entries The data driven approach has also been studied e g pattern extraction using automatic phone recognition 22 Most of the previous work however has assumed that the domain and lexicon for the training data are the same as those of the test set Pronunciation modeling for spoken Japanese was studied using the CSJ 5 Faithful pronunciations of all speech materials in the CSJ have been transcribed as well as orthographic transcriptions Thus pronunciation variations observed in spontaneous speech can be extracted by matching these two kinds of transcriptions Nanjo and Kawahara have already addressed pronunciation modeling using the CSJ 23 where matching was done word by word and the pronunciation probability was estimated for all possible pronunciation variants of a word They also investigated language modeling that separately handled pronunciation variants 23 However these word based approaches are obviously limited to the vocabulary observed in the CSJ and cannot be applied to different tasks We investigate subword based modeling to achieve portability to other domains Pronunciation variation can be described as the transformation of one subword to another Surface forms are obtained by applying such a model to subword sequences of baseforms The decision tree 24 neural network 25 and confusion matrix 26 have been proposed as the modeling frameworks Phones are often used as the modeling units Although pronunciation variations depend on preceding and following contexts most methods have not considered the context or have only counted neighboring phones Moreover the three methods mentioned above Fig 3 Flow of pronunciation model transformation The proposed modeling method involves three steps First patterns in pronunciation variations are detected and the necessary statistics for variation patterns and their phone contexts are estimated Next a set of rewrite rules is derived with appropriate contexts and probabilities Finally these rules are applied to baseforms to generate new pronunciation entries surface forms A Extraction of Pronunciation Variations First phonetic transcriptions of spoken words in the training data are compared with baseforms to detect pronunciation variations The input text must be segmented into words to make comparisons and each word must have a pronunciation baseform In Japanese morphological analysis is applied to the input text to insert word boundaries and generate baseforms Then baseforms and phonetic transcriptions surface forms are automatically aligned for each word using a dynamic programming technique given utterance boundaries As Japanese words often have distinct multiple baseforms the most likely baseform is also determined by the alignment process As we can see from Fig 3 if a mismatched pair of a baseform and a surface form i e variant is found their phone sequences are identified Each variation is extracted together with its preceding and following phone context and the number of times it occurs is counted We considered up to two phones in both directions as the phone context The length of the context seemed reasonable since at most five phones quinphones are used as a modeling unit in context dependent acoustic modeling Note that the word boundary is also considered as a context because it provides useful information for pronunciation variations B Generation of Probabilistic Rewrite Rules Next probabilistic rewrite rules are generated based on the statistics of variations obtained in the previous step Let be a certain phone or phone sequence with phone context and be a variant of and correspond to the occurrence counts of baseform and surface form with to determine context A threshold is introduced for the adequate length of context so that the model has reliable statistics Namely patterns that are more frequent than i e 1544 IEEE TRANSACTIONS ON AUDIO SPEECH AND LANGUAGE PROCESSING VOL 18 NO 6 AUGUST 2010 TABLE II EXAMPLES OF SPOKEN STYLE EXPRESSIONS AND THEIR OCCURRENCE COUNTS IN CONGRESSIONAL SPEECH are adopted as rules and their probabilities are computed as 10 are The contextual patterns eliminated by the threshold backed off to shorter context rules We used at most two phones as preceding and following contexts Let and be the respective lengths of the preceding be a set of rules whose conand following contexts and text length is and Rules are defined in a descending order to a context independent rule from the longest context set These once adopted should be excluded from the back off computation For example the adjusted frequency of variation which has preceding context and pattern following context is computed as 11 is all variation patterns applicable to the input where entry and the initial probabilities of are equal i e one divided by the number of baseforms The rules are applied to every possible position in the baseform and the probability of a new entry is calculated by multiplying probabilities of the actually applied rules to derive from 12 On the other hand the total amount of probabilities assigned to these new entries is deducted from the initial probability of the baseform entry 13 A resulting entry is discarded if its probability is smaller than a threshold to avoid false matching with rare entries during a decoding process V ANALYSIS ON CHARACTERISTICS OF SPONTANEOUS JAPANESE This section investigates spoken and formal Japanese using parallel aligned corpora to clarify the differences between them The comparison is made in lexical and phonetic sequences Note that we did not analyze the inversion and disorder of phrases and sentences as these were beyond the scope of N gram based LVCSR A Linguistic Characteristics in Spontaneous Japanese We used transcriptions and the minutes of congressional meetings as a parallel corpus for the lexical comparison We prepared faithful transcriptions of speech from meetings in the House of Representatives of the National Diet of Japan Most of the speech was extracted from the budget committee in 2003 where a variety of national issues were discussed Committee meetings in the Diet are more spontaneous than plenary sessions in parliament which were mainly dealt in the TC STAR project The House provides minutes of its meetings which were edited to meet the strict orthographic standards by professional stenographers They are not faithful transcripts since redundant expressions such as fillers and end of sentence expressions are deleted and several spoken expressions are modified for purposes of documentation They were manually compared and aligned to faithful transcriptions of the original speech and each edit was annotated The transcripts in this analysis contained 737 K words Table II lists typical differences and their occurrences in the parallel aligned corpus The most significant phenomenon in spontaneous speech is the insertion of fillers and end of sentence expressions as listed in Table II a A similar tendency has been reported in lectures in the CSJ 28 As these kinds of end of sentence expressions and conjunctives are often treated as fillers many such expressions are removed from minutes The rewrite rules for variation consist of context and individual rule entries have their sets Finally we also introduce a own probabilities threshold for the probabilities and rules that have probabilities larger than i e are adopted This threshold is intended to save computation at the time of application by discarding trivial rewrite rules C Application of Variation Rules Then new surface forms are generated by applying the set of rules to baseforms in a lexicon 1 Rules with longer contexts are applied with higher priority and then backed off to shorter contexts if necessary The probabilities of a resulting new pronunciation entry and the original for a lexical entry are updated as 12 and 13 1Using a finite state transducer FST would realize a more solid implementation but it was not adopted in this work AKITA AND KAWAHARA STATISTICAL TRANSFORMATION OF LANGUAGE AND PRONUNCIATION MODELS FOR SPONTANEOUS SPEECH RECOGNITION 1545 TABLE III EXAMPLES OF PRONUNCIATION VARIATIONS EXTRACTED FROM THE CSJ The deletions and substitutions in Table II b and c occur fewer times than insertions but have typical patterns Most deletions are postpositional particles which indicate the relationship between words or phrases such as the linguistic case structures Note that not all postpositional particles are deleted e g those indicating the nominative case such as wa and ga are often omitted while those indicating the possessive case are rarely dropped Lexical substitutions with colloquial expressions are often used for short smooth utterances just as the contracted forms of can t and ain t are often used in English conversation A large number of such substitutions appear at the ends of sentences which corresponds to verbs and auxiliary verbs in Japanese B Pronunciation Variations in Spontaneous Japanese We used the CSJ for phonetic comparison which has faithful transcriptions of speech from lectures We generated an orthographic pronunciation of speech using a morphological dictionary and then compared it against the faithfully transcribed pronunciation A total of 630 K words was used for this analysis Typical variations in the CSJ are listed in Table III One of the major differences occurs in vowels i e a short vowel or a diphthong becomes a long vowel and a long vowel becomes a short vowel Japanese syllables typically consist of a consonant followed by a vowel therefore vowels surrounded by consonants typically k sometimes vanish glottal stop Most of these variations cause us to speak faster Unvoiced consonants are often voiced in compound words of nouns However some consonants are also dropped to simplify pronunciation in limited phone contexts Some examples of derived rewrite rules are listed in Table IV The derived rule set includes typical cases of pronunciation variations that are phonologically predictable e g e i e diphthong to long vowel and k u q vanishing vowel However our results attach appropriate probabilities to these Moreover a number of variants that are characteristic to spontaneous speech and cannot be predicted by using phonology were also found VI EXPERIMENTAL EVALUATIONS We carried out experiments on real congressional speech to evaluate the proposed transformation schemes of language and pronunciation models First we preliminarily examined three modeling schemes for transforming the language model and TABLE IV EXAMPLES OF REWRITE RULES denotes word boundary they were then compared with conventional methods Finally we transformed the pronunciation model and evaluated it A Comparison of Methods of Transforming Language Model We preliminarily evaluated how effective the back off linearinterpolation and ME based methods were for transforming the language model We collected archives of the minutes of the National Diet over four years 1546 IEEE TRANSACTIONS ON AUDIO SPEECH AND LANGUAGE PROCESSING VOL 18 NO 6 AUGUST 2010 TABLE V PERPLEXITY FOR BUDGET COMMITTEE MEETING TEST SET TABLE VI SPECIFICATIONS OF 2006 CONGRESSIONAL SPEECH TEST SET TABLE VII SPECIFICATIONS OF LANGUAGE MODELS tuned depending on characteristics of and the target domain For the reference models in this experiment the best interpolation weight was separately chosen based on the perplexity over the test set 2 The perplexity PP out of vocabulary OOV rates and numbers of bigram and trigram entries for the two mixture models and the three transformed models are listed in Table V The combination with CSJ CSJ improved the perplexity and the OOV rate however the improvement against the baseline was smaller because it could not provide sufficient N gram entries for this task In contrast the combination with transcripts of the parallel corpus Transcript considerably improved perplexity These transcripts matched the task and N gram entries in the transcripts well covered spoken expressions in the test set although the increase of N gram entries was small All transformed models further reduced perplexity Among these models the back off model achieved smallest perplexity The reduction by this model over the baseline model was 37 5 and that over the conventional CSJ model was 34 1 The reduction over the Transcript model was 7 7 It was confirmed that the proposed transformation generated more N gram entries than the mixture based models and it led to these improvements We also confirmed that most of these N gram entries were generated by the POS based transformation When POS based transformation was omitted and word based transformation was solely applied only 3 70 M trigram entries were obtained and perplexity by this model was 75 2 When we compare the three transformed models there were fewer trigram entries in the linear interpolation model than in the other two transformed models because the effect of POS based transformation was reduced by the interpolation The ME model generated more N gram entries than the back off model however the perplexity by the former was larger Because the set of features for the ME model seemed too large the parameters could not be estimated appropriately Based on the results we adopted the back off scheme for transforming the language model B Transformation of Language Model in Different Topic Domains We applied the proposed transformation model to different topic domains in the National Diet to evaluate the generality We prepared new test sets for various committee meetings held in 2006 including those of the budget committee as listed in 2We did not prepare held out data for tuning but this would give a positive bias to the reference models Table VI There were a total of five meetings and the test set transcripts contained 144 K words in total The transformation model was retrained for this experiment using the entire parallel corpus 737 K explained in Section V A We obtained 6339 transformation patterns and 2310 36 of these were POS based We also enhanced the baseline language model used in the previous experiment by adding the minutes for year 2003 to 2005 to the training texts Then conventional mixture models were created by combining it with the transcripts in the CSJ or the parallel corpus Best mixture weights were preliminarily chosen for these models using perplexity on the test set The transformed model was generated based on the back off scheme The specifications for all models are listed in Table VII These models except the baseline model have the same vocabulary of 54 321 items The difference between this vocabulary and the baseline vocabulary was mostly fillers that were found only in the transcripts of the parallel aligned corpus The transformation added these words to the baseline vocabulary and resulting vocabulary was also applied to the mixture models The average OOV rate by this vocabulary over the test set is 0 15 as shown in Table VI Note that the baseline model was only used to mix with the other models and not to directly evaluate as it was obviously inappropriate for speech recognition The acoustic model in this experiment was newly trained using 140 hours of speech from meetings in the Diet with applying vocal tract length normalization VTLN 29 30 and minimum phone error MPE training 31 As we can see from Fig 4 perplexity was drastically reduced by the Proposed model over the CSJ and Transcripts models in all meetings The average perplexity by CSJ Transcripts and Proposed models corresponded to 52 0 49 1 and 41 2 Reduction in perplexity by the transformed model was 20 8 against the CSJ model and 16 1 against the Transcripts model Although the CSJ model had many more trigram entries 7 29 M than the other two models its perplexity was larger This suggests that a simple AKITA AND KAWAHARA STATISTICAL TRANSFORMATION OF LANGUAGE AND PRONUNCIATION MODELS FOR SPONTANEOUS SPEECH RECOGNITION 1547 Fig 4 Perplexity by language models Fig 5 Word error rates by language models mixture based language model does not sufficiently cover effective N gram entries The Transcripts model reduced perplexity over the CSJ model however the reduction was relatively smaller This is because mixture with the transcript yielded a limited number of trigram entries This result demonstrated efficient and effective prediction could be accomplished with the proposed transformation The reduction in perplexity with the proposed model against the Transcripts model was larger in this experiment than that obtained in the previous experiment 6 9 where the training and test set data were taken from the same budget committee and the date of the meetings were close Since the topics in both data were similar the mixture based Transcripts model could accomplish high coverage and small perplexity In contrast the test data in this experiment were chosen from a different year and thus the topics were also different even in the same budget committee While the Transcripts model could not greatly reduce perplexity the proposed model accomplished significant perplexity reduction This means that the proposed approach is general and even more effective in different topic domains Fig 5 is a bar graph of the word error rates WER for the three language models Here we used a pronunciation lexicon without the surface forms provided by our method that were described in Section IV The WERs obtained by the CSJ and Transcripts models were comparable whereas the proposed Transformed model significantly reduced the WER The reduced WER by using the Transformed model over the CSJ and Transcript models corresponded to 3 2 and 2 8 relative and these were statistically signifi The proposed method particularly reduced cant at errors around the fillers which might be inserted at many points The mixture based approach achieved limited error reduction around fillers since it could only provide N gram entries observed in the training corpus Actually we conducted an evaluation in which fillers were removed from automatic speech recognition ASR results and reference texts before comparison Here we obtained WERs of 21 6 21 5 and 20 9 by CSJ Transcripts and Transformed models respectively Improvements by the proposed transformation over CSJ and Transcripts models were 3 1 and 2 6 relative which were still statistically significant at This result demonstrates the advantage of the proposed method i e it could predict unseen N gram entries in the training corpus C Effect of Training Data Size In the proposed transformation the size of training data might affect the performance of the transformed language model To investigate this we made another experiment using transformation models that were trained with a half a quarter and one eighth portions of the parallel aligned corpus Average perplexity over the test set by language models transformed with these models were 42 0 43 1 and 44 4 respectively while the full size model achieved 41 2 as mentioned above This result suggests that the proposed method properly works even if the size of training data is one eighth i e smaller than 100 K words and the performance was almost saturated with the 737 K corpus D Transformation of Pronunciation Model Using the CSJ Finally we evaluated the proposed transformation scheme of the pronunciation model We used the CSJ in Section V B to train the transformation model We used all lectures in the CSJ 6 3 M words Thresholds and were determined as and based on our previous experiments on discussion tasks 32 As a result 265 kinds of variation patterns and 1381 rules were obtained By applying these rules the lexicon of 57 462 baseform entries was expanded to 64 857 entries by adding 7395 surface forms Fig 6 is a bar chart of the WER on the same test set by using the baseline pronunciation lexicon and the transformed lexicon which contains surface forms generated by the rewrite rules The Transformed language model in Table VII was used in this experiment Reduced WER was achieved in all meetings and the average reduction was relatively 4 6 This reduction is statis The training data used for the tically significant at transformation model was the CSJ which had a completely different domain from the Diet task Therefore the results demonstrated that the proposed framework could model spontaneous characteristics separately from the domain characteristics of the training data and achieved portability to other task domains The average WER by transforming the language and pronunciation models was 20 2 The improvement in both transformations over the CSJ language model and the baseline pronunciation lexicon was relatively 7 6 which is almost the 1548 IEEE TRANSACTIONS ON AUDIO SPEECH AND LANGUAGE PROCESSING VOL 18 NO 6 AUGUST 2010 REFERENCES 1 G Zavaliagkos J McDonough D Miller A El Jaroudi J Billa F Richardson K Ma M Siu and H Gish The BBN Byblos 1997 large vocabulary conversational speech recognition system in Proc ICASSP 1998 pp Fig 6 Word error rates by pronunciation models same as the sum of individual improvement 3 2 and 4 6 This means that two transformations could work synergistically and effectively improved LVCSR VII CONCLUSION We proposed a novel approach of statistical transformation that efficiently generated a language and a pronunciation model for spontaneous speech recognition The transformation model for the language model contained context dependent probabilistic patterns of transformation from document style to spontaneous speech These patterns and their probabilities were determined based on occurrence statistics in a parallel corpus of faithful transcripts and their corresponding document style texts Since these training data were small contexts were backed off to the POS level which provided more robust prediction The transformation model was applied to the N gram counts of a document style language model and N gram entries for spontaneous speech were generated with the estimated number of occurrences The transformation model for a pronunciation model consisted of probabilistic rewrite rules with phone contexts of variable lengths The pronunciation variations between baseform and surface forms were extracted from a large scale spontaneous speech corpus CSJ then phone context dependent variation patterns and their occurrence probabilities were trained Since the probabilistic model was generalized it can be applied to any lexicon of new domains to generate appropriate surface forms with their probabilities In experimental evaluations on real congressional speech the proposed method efficiently and effectively generated a language model and a pronunciation model and reduced both perplexity and WER The transformed language model was tested on meetings whose topics and times were different from those in the training data and it accomplished reduced WER without side effects of increasing vocabulary The result demonstrated the generality of the proposed transformation of language model for new domains As for pronunciation model the transformation model was trained with the CSJ and tested on the Diet corpus Although the two corpora were completely different the generated pronunciation model reduced WER This clearly demonstrated the portability of our approach and thus transformation is expected to be applied to any spontaneous speech recognition tasks AKITA AND KAWAHARA STATISTICAL TRANSFORMATION OF LANGUAGE AND PRONUNCIATION MODELS FOR SPONTANEOUS SPEECH RECOGNITION 1549 26 D Torre L Villarrubia J Elvira and L Hernandez Gomez Automatic alternative transcription generation and vocabulary selection for flexible word recognizers in Proc ICASSP 1997 pp Tatsuya Kawahara M 